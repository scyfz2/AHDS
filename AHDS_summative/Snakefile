import os
from glob import glob
# Load configuration file
configfile: "config/config.yaml"

# Directories
RAW_DIR = config["raw_dir"]
ARTICLES_DIR = config["articles_dir"]
PROCESSED_DIR = config["processed_dir"]
CLEAN_DIR = config["clean_dir"]

# Keywords and parameters
KEYWORD = config["keyword"].replace(" ", "%20")  # Replace spaces with URL encoding
RETMAX = config["retmax"]


# Helper function: Extract PMIDs from XML
def get_pmids():
    import xml.etree.ElementTree as ET
    try:
        pmids_file = os.path.join(RAW_DIR, "pmids.xml")
        tree = ET.parse(pmids_file)
        root = tree.getroot()
        pmid_list = [id_elem.text for id_elem in root.findall(".//Id")]
        if not pmid_list:
            raise ValueError("No PMIDs found in pmids.xml")
        return pmid_list
    except Exception as e:
        print(f"Error parsing PMIDs from {pmids_file}: {e}")
        return []

# Rule: All
rule all:
    input:
        os.path.join(RAW_DIR, "pmids.xml"),
        expand(os.path.join(ARTICLES_DIR, "article-data-{pmid}.xml"), pmid=get_pmids()),
        os.path.join(PROCESSED_DIR, "articles.tsv"),
        os.path.join(CLEAN_DIR, "cleaned_articles.tsv")


# Rule: fetch data
rule fetch_data:
    output:
        os.path.join(RAW_DIR, "pmids.xml"),
        "logs/fetch_data.log"
    shell:
        """
        bash scripts/fetch_data.sh '{KEYWORD}' {RETMAX} {RAW_DIR} {ARTICLES_DIR}
        """

# Rule: Process XML files into TSV
rule process_articles:
    input:
        f"logs/fetch_data.log",
        expand(os.path.join(ARTICLES_DIR, "article-data-{pmid}.xml"), pmid=get_pmids())
    output:
        os.path.join(PROCESSED_DIR, "articles.tsv"),
        "logs/process_articles.log"
    shell:
        """
        Rscript scripts/process_articles.R {ARTICLES_DIR} {output}
        """

# Rule: Clean Titles using tidytext
rule clean_titles:
    input:
        f"logs/process_articles.log",
        os.path.join(PROCESSED_DIR, "articles.tsv")
    output:
        os.path.join(CLEAN_DIR, "cleaned_articles.tsv"),
        "logs/clean_titles.log"
    script:
        "scripts/clean_titles.R" 


rule visualize_trends:
    input:
        "data/processed/cleaned_articles.tsv"
    output:
        "data/visualizations/word_trends.png"
    script:
        "scripts/visualize_trends.R"


# Rule: remove data and logs directory
rule clean:
    "Clean up"
    shell: """
    if [ -d data ]; then
      rm -r data
    else
      echo directory data does not exist
    fi
    if [ -d logs ]; then
      rm -r logs
    else
      echo directory logs does not exist
    fi
    """
