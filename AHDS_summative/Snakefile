import os

configfile: "config/config.yaml"

# Directories
RAW_DIR = config["raw_dir"]
ARTICLES_DIR = config["articles_dir"]
PROCESSED_DIR = config["processed_dir"]

# Keywords and parameters
KEYWORD = config["keyword"].replace(" ", "%20")  # 替换空格为 URL 编码
RETMAX = config["retmax"]

# Helper function: Extract PMIDs from XML
def get_pmids():
    import xml.etree.ElementTree as ET
    try:
        pmids_file = os.path.join(RAW_DIR, "pmids.xml")
        tree = ET.parse(pmids_file)
        root = tree.getroot()
        pmid_list = [id_elem.text for id_elem in root.findall(".//Id")]
        if not pmid_list:
            raise ValueError("No PMIDs found in pmids.xml")
        return pmid_list
    except Exception as e:
        print(f"Error parsing PMIDs from {pmids_file}: {e}")
        return []

# Rule: All
rule all:
    input:
     os.path.join(RAW_DIR, "pmids.xml"),
        expand(os.path.join(ARTICLES_DIR, "article-data-{pmid}.xml"), pmid=lambda wildcards: get_pmids())

        # os.path.join(PROCESSED_DIR, "articles.tsv")

# Rule: Fetch PubMed IDs
rule fetch_pmids:
    output:
        RAW_DIR + "/pmids.xml"
    shell:
        """
        bash scripts/fetch_pmids.sh '{KEYWORD}' {RETMAX} {output}
        """

# Rule: Fetch Articles
rule fetch_articles:
    input:
        RAW_DIR + "/pmids.xml"
    output:
        ARTICLES_DIR + "/article-data-{pmid}.xml"
    shell:
        """
        bash scripts/fetch_articles.sh "{wildcards.pmid}" "{output}"
        """

# Rule: Process XML files into TSV
rule process_articles:
    input:
        expand(os.path.join(ARTICLES_DIR, "article-data-{pmid}.xml"), pmid=get_pmids())
    output:
        os.path.join(PROCESSED_DIR, "articles.tsv")
    shell:
        """
        Rscript scripts/process_articles.R {ARTICLES_DIR} {output}
        """

# Rule: Clean Titles using tidytext
rule clean_titles:
    input:
        "data/processed/articles.tsv"
    output:
        "data/processed/cleaned_articles.tsv"
    script:
        "scripts/clean_titles.R"


rule visualize_trends:
    input:
        "data/processed/cleaned_articles.tsv"
    output:
        "data/visualizations/word_trends.png"
    script:
        "scripts/visualize_trends.R"



rule clean:
    "Clean up"
    shell: """
    if [ -d data ]; then
      rm -r data
    else
      echo directory data does not exist
    fi
    if [ -d intermediates ]; then
      rm -r intermediates
    else
      echo directory intermediates does not exist
    fi
    """
